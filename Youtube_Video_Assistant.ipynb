{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVH5lXrcB89WSherSCPNxu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Install and Import Required Libraries"
      ],
      "metadata": {
        "id": "bfpOIaZ-4Ifg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Install Necessary Libraries\n",
        "!pip install -q youtube-transcript-api langchain-community langchain-google-genai faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vwdwes6g4xdd",
        "outputId": "9b4581bb-c05e-4b42-d917-04387742c0cc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m1.9/2.2 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XiCUgQ5c4AgV"
      },
      "outputs": [],
      "source": [
        "## Import Libraries\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from google.colab import userdata\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the API key from Google Colab Secrets\n",
        "api_token = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "# set the API Key and print\n",
        "os.environ['GOOGLE_API_KEY'] = api_token\n",
        "# print(api_token)"
      ],
      "metadata": {
        "id": "lV5_sLAY4XLE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Document Ingestion\n",
        "##### First we will fetch the transcript of the video using YouTubeTranscriptApi."
      ],
      "metadata": {
        "id": "EmX-WJSZ5yQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## provide the video ID\n",
        "youtube_video_id = 'Gfr50f6ZBvo'\n",
        "\n",
        "try:\n",
        "    ## specifies the language in which video in\n",
        "    transcript_list = YouTubeTranscriptApi.get_transcript(youtube_video_id, languages=['en'])\n",
        "    print(transcript_list[0:2])\n",
        "except Exception as e:\n",
        "    print(f\"Error Occured in Transcription: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwwrEd1S5uLL",
        "outputId": "71089bc8-dd2d-4b23-e5b4-0f8e73696463"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'text': 'the following is a conversation with', 'start': 0.08, 'duration': 3.44}, {'text': 'demus hasabis', 'start': 1.76, 'duration': 4.96}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## combine the list to get the full text\n",
        "transcript = \" \".join([text_dict['text'] for text_dict in transcript_list])\n",
        "# print(transcript)"
      ],
      "metadata": {
        "id": "HX_RtwgN7OMT"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Split the transcript text into small chunks for better search\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "text_chunks = text_splitter.create_documents([transcript])\n",
        "print(len(text_chunks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYaqq-QR-OQo",
        "outputId": "8a4e05f4-fd3c-444a-f762-e4436da71bab"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l67LoJmh_CcV",
        "outputId": "1871cd70-9cdf-4d2d-e09d-5a64536ac486"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={}, page_content=\"the following is a conversation with demus hasabis ceo and co-founder of deepmind a company that has published and builds some of the most incredible artificial intelligence systems in the history of computing including alfred zero that learned all by itself to play the game of gold better than any human in the world and alpha fold two that solved protein folding both tasks considered nearly impossible for a very long time demus is widely considered to be one of the most brilliant and impactful humans in the history of artificial intelligence and science and engineering in general this was truly an honor and a pleasure for me to finally sit down with him for this conversation and i'm sure we will talk many times again in the future this is the lex friedman podcast to support it please check out our sponsors in the description and now dear friends here's demis hassabis let's start with a bit of a personal question am i an ai program you wrote to interview people until i get good enough\")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding and Store\n",
        "##### Generate the embedding of the text chunks and store them in a vector store for future retrival"
      ],
      "metadata": {
        "id": "2PVx2xsO_Vam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## create the embeddings of the text chunks and store them in FAISS vector store\n",
        "chunks_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "print(chunks_embeddings)\n",
        "\n",
        "# Create FAISS vector store from documents\n",
        "faiss_vector_store = FAISS.from_documents(text_chunks, chunks_embeddings)\n",
        "\n",
        "# Check how many vectors are in the index\n",
        "print(faiss_vector_store.index.ntotal)"
      ],
      "metadata": {
        "id": "-i4-aZxm_GF0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb1b73e9-4cbf-4ce3-d8e1-fc6857a8a53e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x798c85785090> model='models/embedding-001' task_type=None google_api_key=SecretStr('**********') credentials=None client_options=None transport=None request_options=None\n",
            "168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## unique id of the text chunks\n",
        "faiss_vector_store.index_to_docstore_id.get(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-_5xWj3VD7l7",
        "outputId": "a37ac560-e0b8-4410-ef21-0ad052390dfc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'85f4b41c-e35b-4cfe-b3ee-acc03fefb0a0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faiss_vector_store.get_by_ids([faiss_vector_store.index_to_docstore_id.get(0)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuaiRkiIC3VH",
        "outputId": "33d9a612-8519-4b23-a27e-60940a43d0e7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='85f4b41c-e35b-4cfe-b3ee-acc03fefb0a0', metadata={}, page_content=\"the following is a conversation with demus hasabis ceo and co-founder of deepmind a company that has published and builds some of the most incredible artificial intelligence systems in the history of computing including alfred zero that learned all by itself to play the game of gold better than any human in the world and alpha fold two that solved protein folding both tasks considered nearly impossible for a very long time demus is widely considered to be one of the most brilliant and impactful humans in the history of artificial intelligence and science and engineering in general this was truly an honor and a pleasure for me to finally sit down with him for this conversation and i'm sure we will talk many times again in the future this is the lex friedman podcast to support it please check out our sponsors in the description and now dear friends here's demis hassabis let's start with a bit of a personal question am i an ai program you wrote to interview people until i get good enough\")]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## by default the chunks embeddings will be stored in the RAM memory, to save the data locally to the disk\n",
        "faiss_vector_store.save_local(\"faiss_vector_store\")\n",
        "## load the data from local\n",
        "faiss_vector_store = FAISS.load_local(\"faiss_index\", chunks_embeddings)"
      ],
      "metadata": {
        "id": "E3TI7SdiHp9B"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_vector = faiss_vector_store.index.reconstruct(0)\n",
        "print(f\"Embedding length: {len(first_vector)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD2dD0ddGGEo",
        "outputId": "88d58277-15b2-4e3e-ec31-fb5dfa607e91"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding length: 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reterival\n",
        "##### To retrive the relevant text chunks we will create a retriver object and on the basis of similarity top k text chunks will be picked and returned."
      ],
      "metadata": {
        "id": "ZAENcLaSIGD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## top 3 text chunks on the basis of similarity\n",
        "retriever = faiss_vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
        "retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mTaj3VwHFhd",
        "outputId": "5364bced-0041-437e-9759-43802b6d6b67"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x798c85888790>, search_kwargs={'k': 3})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.invoke('What is deepmind.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f1Eh5G8IrVr",
        "outputId": "d0e7c361-7804-41cf-ed52-36a62431c17a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='ae767766-dce6-41bc-9a2d-19c0f750c412', metadata={}, page_content=\"that are amazingly smart at certain things like maybe playing go and chess and other things but they don't feel at all in any shape or form conscious in the way that you know you do to me or i do to you and um and i think actually building ai is uh these intelligent constructs uh is one of the best ways to explore the mystery of consciousness to break it down because um we're going to have devices that are pretty smart at certain things or capable of certain things but potentially won't have any semblance of self-awareness or other things and in fact i would advocate if there's a choice building systems in the first place ai systems that are not conscious to begin with uh are just tools um until we understand them better and the capabilities better so on that topic just not as the ceo of deep mind just as a human being let me ask you about this one particular anecdotal evidence of the google engineer who made a comment or believed that there's some aspect of a language model the\"),\n",
              " Document(id='60c35d4f-e161-4c39-86e7-e560849f9064', metadata={}, page_content=\"ambitious as trying to solve intelligence and you're you're you know it's blue sky research no one knows how to do it you you you need to use any evidence or any source of information you can to help guide you in the right direction or give you confidence you're going in the right direction so so that that was one reason we pushed so hard on that and that's and just going back to your early question about organization the other big thing that i think we innovated with at deepmind to encourage invention and and uh and innovation was the multi-disciplinary organization we built and we still have today so deepmind originally was a confluence of the of the most cutting-edge knowledge in neuroscience with machine learning engineering and mathematics right and and gaming and then since then we built that out even further so we have philosophers here and and uh by you know ethicists but also other types of scientists physicists and so on um and that's what brings together i tried to build a\"),\n",
              " Document(id='0663a2c5-6f6e-4ecf-8b2a-5e4c1fc7d26c', metadata={}, page_content=\"used of ai is in deep mind from the beginning which is using games as a testing ground for proving out ai algorithms and developing ai algorithms and that was a that was a sort of um a core component of our vision at the start of deepmind was that we would use games very heavily uh as our main testing ground certainly to begin with um because it's super efficient to use games and also you know it's very easy to have metrics to see how well your systems are improving and what direction your ideas are going in and whether you're making incremental improvements and because those games are often rooted in something that humans did for a long time beforehand there's already a strong set of rules like it's already a damn good benchmark yes it's really good for so many reasons because you've got you've got you've got clear measures of how good humans can be at these things and in some cases like go we've been playing it for thousands of years um and and uh often they have scores or at least\")]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Augmentation\n",
        "##### Prepare the prompt with the help of context and query"
      ],
      "metadata": {
        "id": "JSMFNsHtI6gK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## define prompt\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "      You are a helpful assistant, who will provide me the answer of the given question on the basis of provided context..\n",
        "      Answer ONLY from the provided transcript context.\n",
        "      If the context is insufficient, just say \"I don't have answer to the specific question.\".\n",
        "\n",
        "      {context}\n",
        "      Question: {question}\n",
        "    \"\"\",\n",
        "    input_variables = ['context', 'question']\n",
        ")"
      ],
      "metadata": {
        "id": "J8svpia3IxAQ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Is the topic of nuclear fusion discussed in this video? if yes then what was discussed?\"\n",
        "retrieved_docs = retriever.invoke(question)"
      ],
      "metadata": {
        "id": "NqL5KOhvJgk3"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## make a single paragraph from retrieved documents\n",
        "context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "context_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "4vJYr0DUJoIy",
        "outputId": "50a7b9d4-9cea-4a5c-800b-b6123d2a8e60"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"in this case in fusion we we collaborated with epfl in switzerland the swiss technical institute who are amazing they have a test reactor that they were willing to let us use which you know i double checked with the team we were going to use carefully and safely i was impressed they managed to persuade them to let us use it and um and it's a it's an amazing test reactor they have there and they try all sorts of pretty crazy experiments on it and um the the the what we tend to look at is if we go into a new domain like fusion what are all the bottleneck problems uh like thinking from first principles you know what are all the bottleneck problems that are still stopping fusion working today and then we look at we you know we get a fusion expert to tell us and then we look at those bottlenecks and we look at the ones which ones are amenable to our ai methods today yes right and and and then and would be interesting from a research perspective from our point of view from an ai point of\\n\\nso we with this problem and we published it in a nature paper last year uh we held the fusion that we held the plasma in specific shapes so actually it's almost like carving the plasma into different shapes and control and hold it there for the record amount of time so um so that's one of the problems of of fusion sort of um solved so i have a controller that's able to no matter the shape uh contain it continue yeah contain it and hold it in structure and there's different shapes that are better for for the energy productions called droplets and and and so on so um so that was huge and now we're looking we're talking to lots of fusion startups to see what's the next problem we can tackle uh in the fusion area so another fascinating place in a paper title pushing the frontiers of density functionals by solving the fractional electron problem so you're taking on modeling and simulating the quantum mechanical behavior of electrons yes um can you explain this work and can ai model and\\n\\nmilliseconds you know to to basically contain what it's going to do next so it seems like a perfect problem if you think of it for like a reinforcement learning prediction problem so uh you know your controller you're gonna move the magnetic field and until we came along you know they were they were doing it with with traditional operational uh research type of uh controllers uh which are kind of handcrafted and the problem is of course they can't react in the moment to something the plasma's doing that they have to be hard-coded and again knowing that that's normally our go-to solution is we would like to learn that instead and they also had a simulator of these plasma so there were lots of criteria that matched what we we like to to to use so can ai eventually solve nuclear fusion well so we with this problem and we published it in a nature paper last year uh we held the fusion that we held the plasma in specific shapes so actually it's almost like carving the plasma into different\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## preapre prompt\n",
        "final_prompt = prompt.invoke({\"context\": context_text, \"question\": question})\n",
        "final_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsVywMqmJua4",
        "outputId": "e7b43eb9-4eb9-471f-e902-680272d4c1f6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringPromptValue(text='\\n      You are a helpful assistant, who will provide me the answer of the given question on the basis of provided context..\\n      Answer ONLY from the provided transcript context.\\n      If the context is insufficient, just say \"I don\\'t have answer to the specific question.\".\\n\\n      in this case in fusion we we collaborated with epfl in switzerland the swiss technical institute who are amazing they have a test reactor that they were willing to let us use which you know i double checked with the team we were going to use carefully and safely i was impressed they managed to persuade them to let us use it and um and it\\'s a it\\'s an amazing test reactor they have there and they try all sorts of pretty crazy experiments on it and um the the the what we tend to look at is if we go into a new domain like fusion what are all the bottleneck problems uh like thinking from first principles you know what are all the bottleneck problems that are still stopping fusion working today and then we look at we you know we get a fusion expert to tell us and then we look at those bottlenecks and we look at the ones which ones are amenable to our ai methods today yes right and and and then and would be interesting from a research perspective from our point of view from an ai point of\\n\\nso we with this problem and we published it in a nature paper last year uh we held the fusion that we held the plasma in specific shapes so actually it\\'s almost like carving the plasma into different shapes and control and hold it there for the record amount of time so um so that\\'s one of the problems of of fusion sort of um solved so i have a controller that\\'s able to no matter the shape uh contain it continue yeah contain it and hold it in structure and there\\'s different shapes that are better for for the energy productions called droplets and and and so on so um so that was huge and now we\\'re looking we\\'re talking to lots of fusion startups to see what\\'s the next problem we can tackle uh in the fusion area so another fascinating place in a paper title pushing the frontiers of density functionals by solving the fractional electron problem so you\\'re taking on modeling and simulating the quantum mechanical behavior of electrons yes um can you explain this work and can ai model and\\n\\nmilliseconds you know to to basically contain what it\\'s going to do next so it seems like a perfect problem if you think of it for like a reinforcement learning prediction problem so uh you know your controller you\\'re gonna move the magnetic field and until we came along you know they were they were doing it with with traditional operational uh research type of uh controllers uh which are kind of handcrafted and the problem is of course they can\\'t react in the moment to something the plasma\\'s doing that they have to be hard-coded and again knowing that that\\'s normally our go-to solution is we would like to learn that instead and they also had a simulator of these plasma so there were lots of criteria that matched what we we like to to to use so can ai eventually solve nuclear fusion well so we with this problem and we published it in a nature paper last year uh we held the fusion that we held the plasma in specific shapes so actually it\\'s almost like carving the plasma into different\\n      Question: Is the topic of nuclear fusion discussed in this video? if yes then what was discussed?\\n    ')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generation\n",
        "##### Create LLM Object and generate the answer"
      ],
      "metadata": {
        "id": "Bu5AARPmKKZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatGoogleGenerativeAI(\n",
        "    model='gemini-2.0-flash',\n",
        "    temperature=0.2\n",
        ")\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La43EoA9KEhh",
        "outputId": "e48f721e-5178-41af-ca3a-f70121b7cea5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), temperature=0.2, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x798cb988fb90>, default_metadata=(), model_kwargs={})"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## call the llm and print generated text\n",
        "answer = model.invoke(final_prompt)\n",
        "print(answer.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWue5LV1Kjds",
        "outputId": "892371de-16b3-4088-eb98-c5a39e6378f3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, nuclear fusion is discussed. The discussion includes:\n",
            "\n",
            "*   Collaboration with EPFL in Switzerland, who allowed use of their test reactor.\n",
            "*   Identifying bottleneck problems in fusion and using AI methods to address them.\n",
            "*   Using AI to control and hold plasma in specific shapes for record amounts of time, which was published in a Nature paper.\n",
            "*   Exploring different plasma shapes for better energy production.\n",
            "*   Talking to fusion startups to identify the next problem to tackle in the fusion area.\n",
            "*   Using reinforcement learning to predict and control the plasma by moving the magnetic field, replacing traditional handcrafted controllers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### By using Chains"
      ],
      "metadata": {
        "id": "mpvSo_GuKwVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(retrieved_docs):\n",
        "    \"\"\"\n",
        "    Formats a list of retrieved documents into a single string.\n",
        "\n",
        "    This function takes a list of text chunks retrieved from a vector store\n",
        "    and concatenates their textual content into a single string, separated by double newlines for readability.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    retrieved_docs : list\n",
        "        A list of document objects, where each object must have a `page_content` attribute containing the text of the document.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    str\n",
        "        A single string containing the combined content of all documents, separated by two newline characters (\"\\n\\n\").\n",
        "    \"\"\"\n",
        "    context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "    return context_text"
      ],
      "metadata": {
        "id": "yDZrVS_MK26G"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## chain1: get the text chunks from vector store and create a single paragarph\n",
        "parallel_chain = RunnableParallel({\n",
        "    'context': retriever | RunnableLambda(format_docs),\n",
        "    'question': RunnablePassthrough()\n",
        "})"
      ],
      "metadata": {
        "id": "Zs0wLUz8LRt-"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parallel_chain.invoke('who is Demis')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgZn3r40LdQl",
        "outputId": "1423f9da-df9d-4e46-8f6e-85aca8b8efbc"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': \"the following is a conversation with demus hasabis ceo and co-founder of deepmind a company that has published and builds some of the most incredible artificial intelligence systems in the history of computing including alfred zero that learned all by itself to play the game of gold better than any human in the world and alpha fold two that solved protein folding both tasks considered nearly impossible for a very long time demus is widely considered to be one of the most brilliant and impactful humans in the history of artificial intelligence and science and engineering in general this was truly an honor and a pleasure for me to finally sit down with him for this conversation and i'm sure we will talk many times again in the future this is the lex friedman podcast to support it please check out our sponsors in the description and now dear friends here's demis hassabis let's start with a bit of a personal question am i an ai program you wrote to interview people until i get good enough\\n\\nout our sponsors in the description and now dear friends here's demis hassabis let's start with a bit of a personal question am i an ai program you wrote to interview people until i get good enough to interview you well i'll be impressed if if you were i'd be impressed by myself if you were i don't think we're quite up to that yet but uh maybe you're from the future lex if you did would you tell me is that is that a good thing to tell a language model that's tasked with interviewing that it is in fact um ai maybe we're in a kind of meta turing test uh probably probably it would be a good idea not to tell you so it doesn't change your behavior right this is a kind of heisenberg uncertainty principle situation if i told you you behave differently yeah maybe that's what's happening with us of course this is a benchmark from the future where they replay 2022 as a year before ais were good enough yet and now we want to see is it going to pass exactly if i was such a program would you be\\n\\ndeeper maybe simpler explanation yes of things right than the standard model of physics which we know doesn't work but we still keep adding to so um and and that's how i think the beginning of an explanation would look and it would start encompassing many of the mysteries that we have wondered about for thousands of years like you know consciousness uh life and gravity all of these things yeah giving us a glimpses of explanations for those things yeah well um damas dear one of the special human beings in this giant puzzle of ours and it's a huge honor that you would take a pause from the bigger puzzle to solve this small puzzle of a conversation with me today it's truly an honor and a pleasure thank you thank you i really enjoyed it thanks lex thanks for listening to this conversation with demas establish to support this podcast please check out our sponsors in the description and now let me leave you with some words from edskar dykstra computer science is no more about computers than\",\n",
              " 'question': 'who is Demis'}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## create parser object\n",
        "parser = StrOutputParser()\n",
        "final_chain = parallel_chain | prompt | model | parser\n",
        "\n",
        "final_chain.invoke('Can you summarize the video')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "Q4BwkDAeLgEQ",
        "outputId": "ffae2ab6-3400-4bf8-fe2a-9b73f09dfd4e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Here is a summary of the video, based on the context you provided:\\n\\nThe speaker discusses finding your unique skills and passions to make a difference in the world. They then transition to questions about a day in the life, including waking habits, coffee consumption, and computer usage. The speaker also touches on fundamental explanations of physics, more careful specifications, and glimpses of things missed in today's physics. They mention a deeper, simpler explanation of things than the standard model. The discussion also involves simulating chemistry, describing electron clouds, and learning a simulation to describe more chemistry types. The goal is to simulate large materials by building functionals that approximate Schrodinger's equation, allowing the description of what electrons are doing and how they interact.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e2PgW3SvLv4I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}